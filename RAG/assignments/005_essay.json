{
  "type": "essay",
  "description": "论述题：请按要求回答以下问题。",
  "score_per_question": 20,
  "questions": [
    {
      "id": 1,
      "stem": "请结合材料，描述在TensorFlow Lite中初始化解释器的步骤，并说明为何要使用静态内存分配。",
      "reference_answer": "初始化TensorFlow Lite解释器的步骤包括：1. 将.tflite模型加载到内存中，该内存包含模型的执行图；2. 设置解释器的参数，例如使用线程的数量；3. 创建一个解释器实例。静态内存分配是指在运行模型时，每个算子执行prepare函数，分配一个单一的内存块，所有张量整合到这个内存块中，甚至可以复用内存。这种分配方式减少了内存碎片和运行时的内存管理开销，提高了执行效率和内存使用效率，特别适合资源受限的移动设备。",
      "grading_criteria": "根据是否能准确描述初始化步骤、是否清楚解释静态内存分配的作用，以及是否结合材料内容进行说明进行评分。"
    },
    {
      "id": 2,
      "stem": "在使用TensorFlow Lite进行模型推理时，数据转换是一个关键环节。请分析数据转换的必要性，并结合例子说明。",
      "reference_answer": "数据转换的必要性在于模型的输入格式和实际数据往往不一致。例如，原始图像的尺寸和通道顺序可能与模型期望的输入格式不同。因此，需要将图像调整到模型所需的尺寸，例如将224x224的RGB图像作为输入，同时可能需要归一化像素值。如果模型期望的是经过特定预处理的图像（如VGG网络的ImageNet预处理），数据转换就尤为重要。此过程确保模型能正确处理输入，从而得到准确的推理结果。",
      "grading_criteria": "根据是否说明数据转换的必要性、是否给出适当例子，以及表达的清晰度进行评分。"
    },
    {
      "id": 3,
      "stem": "结合材料中的模型参数信息（Total params, Trainable params, Non-trainable params），试分析微调（Fine-tuning）的目的以及其对移动端深度学习应用的意义。",
      "reference_answer": "微调的目的是在保留预训练模型已学习的通用特征的同时，通过训练少量顶层来适应新数据集。例如，材料中提到微调的非训练参数（Non-trainable params）远多于可训练参数（Trainable params），说明大部分特征是通用的，仅需调整顶层即可。这在移动端深度学习应用中意义重大，因为训练全部参数会消耗大量计算资源和训练时间，而微调可以减小模型更新的范围，提高效率，同时避免预训练模型在大量梯度更新中忘记已学到的通用特征，从而在移动设备上实现高性能、低资源消耗的推理。",
      "grading_criteria": "根据是否理解微调目的、是否结合参数数据进行分析，以及是否阐述其在移动端应用中的意义进行评分。"
    }
  ]
}