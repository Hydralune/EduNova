{
  "title": "课程 005期末考试",
  "course": "课程 005",
  "duration": "120分钟",
  "total_score": 120,
  "sections": [
    {
      "type": "multiple_choice",
      "description": "选择题：请在每小题给出的选项中选出一个正确答案。",
      "score_per_question": 4,
      "questions": [
        {
          "id": 1,
          "stem": "在使用迁移学习进行花卉识别时，为什么要冻结预训练模型的基础部分？",
          "options": [
            "A. 为了加快训练速度",
            "B. 为了防止模型参数丢失",
            "C. 为了保留大规模训练中学到的通用特征",
            "D. 为了增加输出层的参数数量"
          ],
          "answer": "C",
          "explanation": "迁移学习中冻结预训练模型的基础部分是为了保留其在大规模数据（如ImageNet）上训练时学到的通用特征，这样只需训练顶部用于具体任务的分类器。"
        },
        {
          "id": 2,
          "stem": "在花卉识别的模型中，瓶颈层的作用是什么？",
          "options": [
            "A. 提取图像的原始像素信息",
            "B. 对图像进行降维处理",
            "C. 将低级特征转换为高级特征",
            "D. 作为图像的输入层"
          ],
          "answer": "C",
          "explanation": "瓶颈层通常位于预训练模型的最后卷积层，是提取高级通用特征的关键部分，在迁移学习中用于生成用于分类的特征向量。"
        },
        {
          "id": 3,
          "stem": "在代码中通过哪一行冻结了基础模型？",
          "options": [
            "A. model = tf.keras.Sequential([base_model, ...])",
            "B. ImageProcessor imageProcessor = new ImageProcessor.Builder()...",
            "C. base_model.trainable = False",
            "D. epochs = 10"
          ],
          "answer": "C",
          "explanation": "通过设置 base_model.trainable = False，可以冻结基础模型的参数，使其在训练过程中不会被更新。"
        },
        {
          "id": 4,
          "stem": "花卉识别应用中，使用GlobalAveragePooling2D层的主要目的是什么？",
          "options": [
            "A. 对图像进行旋转处理",
            "B. 在展平前对特征图进行平均降维",
            "C. 将卷积层转换为全连接层",
            "D. 提取图像边缘信息"
          ],
          "answer": "B",
          "explanation": "GlobalAveragePooling2D层用于在展平操作之前对特征图进行空间平均降维，从而生成一个固定长度的特征向量，便于后续分类操作。"
        },
        {
          "id": 5,
          "stem": "在构建花卉识别模型时，输出层应该有多少个节点？",
          "options": [
            "A. 512",
            "B. 1000",
            "C. 5",
            "D. 1280"
          ],
          "answer": "C",
          "explanation": "输出层应与目标类别数量一致，因此在花卉识别任务中，输出层有5个节点，对应5种花卉类别。"
        },
        {
          "id": 6,
          "stem": "下面哪个代码片段用于对输入图片进行预处理？",
          "options": [
            "A. model.fit(train_generator, steps_per_epoch=len(train_generator), ...)",
            "B. ImageProcessor imageProcessor = new ImageProcessor.Builder().add(new ResizeWithCropOrPadOp(cropSize, cropSize))",
            "C. base_model.trainable = False",
            "D. GlobalAveragePooling2D"
          ],
          "answer": "B",
          "explanation": "ImageProcessor.Builder() 构建的代码片段用于对输入图像进行预处理，例如调整图像大小以适应模型输入需求。"
        },
        {
          "id": 7,
          "stem": "在运行花卉识别模型时，‘执行推理’阶段主要包含以下哪项操作？",
          "options": [
            "A. 更新模型权重",
            "B. 训练全连接层",
            "C. 创建解释器并分配张量",
            "D. 导出模型为SavedModel格式"
          ],
          "answer": "C",
          "explanation": "执行推理阶段需要使用API来创建TensorFlow Lite解释器，并分配相关的张量，以便在设备上运行模型。"
        },
        {
          "id": 8,
          "stem": "TensorFlow Lite转换器的主要作用是什么？",
          "options": [
            "A. 用于数据预处理",
            "B. 用于将Keras模型转换为TFLite格式",
            "C. 用于微调模型的权重",
            "D. 用于训练模型"
          ],
          "answer": "B",
          "explanation": "TensorFlow Lite转换器可以将训练好的Keras模型转换为TensorFlow Lite模型（.tflite文件），以便在移动端部署。"
        },
        {
          "id": 9,
          "stem": "在Android应用中部署TensorFlow Lite模型，通常需要配置哪个构建文件？",
          "options": [
            "A. AndroidManifest.xml",
            "B. build.gradle",
            "C. settings.gradle",
            "D. project.properties"
          ],
          "answer": "B",
          "explanation": "Android应用中使用TensorFlow Lite模型需要在build.gradle文件中添加相关依赖，例如TFLite支持库和模型文件。"
        },
        {
          "id": 10,
          "stem": "以下哪一项不是TensorFlow Lite解释执行器的特点？",
          "options": [
            "A. 低内存占用",
            "B. 支持多平台部署",
            "C. 需要模型被转换为FlatBuffers格式",
            "D. 提供无限训练功能"
          ],
          "answer": "D",
          "explanation": "TensorFlow Lite解释执行器适用于在边缘设备上运行模型，具有低内存和高效执行的特点，但它不能用于模型的训练。"
        }
      ]
    },
    {
      "type": "fill_in_blank",
      "description": "填空题：请在横线上填写正确的内容。",
      "score_per_question": 4,
      "questions": [
        {
          "id": 1,
          "stem": "TensorFlow Lite的解释执行器在内存规划方面采用的是_____, 这样可以避免运行时的动态内存分配。",
          "answer": "静态内存分配",
          "explanation": "TensorFlow Lite的解释执行器在运行模型时，每个算子会执行prepare函数并分配一个单一的内存块，以便提高内存效率。"
        },
        {
          "id": 2,
          "stem": "TensorFlow Lite支持库中的getTopKProbability（..）方法用于从_____, 提取前几名最可能的标签。",
          "answer": "labeledProbability",
          "explanation": "labeledProbability是将每个类别映射到其概率的对象，getTopKProbability方法通过解析该对象来提取最可能的标签。"
        },
        {
          "id": 3,
          "stem": "在使用TensorFlow Lite模型进行推理之前，通常需要对输入数据进行处理，例如调整图像大小或更改图像格式，以完成_____, 的过程。",
          "answer": "数据转换",
          "explanation": "由于模型的输入格式可能与原始数据不一致，因此需要对数据进行转换，以确保模型能够正确运行。"
        },
        {
          "id": 4,
          "stem": "TensorFlow Lite模型文件使用的数据格式是_____,，这是一种高效的二进制序列化格式。",
          "answer": "FlatBuffers",
          "explanation": "FlatBuffers是一种高效的二进制序列化格式，用于存储TensorFlow Lite模型文件。"
        },
        {
          "id": 5,
          "stem": "在TensorFlow Lite的执行过程中，算子之间没有_____,，但算子内部可以多线程执行以提高效率。",
          "answer": "并行执行",
          "explanation": "TensorFlow Lite的快速启动特性意味着算子之间没有并行执行，但算子内部可使用多线程执行提高效率。"
        }
      ]
    },
    {
      "type": "essay",
      "description": "论述题：请按要求回答以下问题。",
      "score_per_question": 20,
      "questions": [
        {
          "id": 1,
          "stem": "请结合材料，描述在TensorFlow Lite中初始化解释器的步骤，并说明为何要使用静态内存分配。",
          "reference_answer": "初始化TensorFlow Lite解释器的步骤包括：1. 将.tflite模型加载到内存中，该内存包含模型的执行图；2. 设置解释器的参数，例如使用线程的数量；3. 创建一个解释器实例。静态内存分配是指在运行模型时，每个算子执行prepare函数，分配一个单一的内存块，所有张量整合到这个内存块中，甚至可以复用内存。这种分配方式减少了内存碎片和运行时的内存管理开销，提高了执行效率和内存使用效率，特别适合资源受限的移动设备。",
          "grading_criteria": "根据是否能准确描述初始化步骤、是否清楚解释静态内存分配的作用，以及是否结合材料内容进行说明进行评分。"
        },
        {
          "id": 2,
          "stem": "在使用TensorFlow Lite进行模型推理时，数据转换是一个关键环节。请分析数据转换的必要性，并结合例子说明。",
          "reference_answer": "数据转换的必要性在于模型的输入格式和实际数据往往不一致。例如，原始图像的尺寸和通道顺序可能与模型期望的输入格式不同。因此，需要将图像调整到模型所需的尺寸，例如将224x224的RGB图像作为输入，同时可能需要归一化像素值。如果模型期望的是经过特定预处理的图像（如VGG网络的ImageNet预处理），数据转换就尤为重要。此过程确保模型能正确处理输入，从而得到准确的推理结果。",
          "grading_criteria": "根据是否说明数据转换的必要性、是否给出适当例子，以及表达的清晰度进行评分。"
        },
        {
          "id": 3,
          "stem": "结合材料中的模型参数信息（Total params, Trainable params, Non-trainable params），试分析微调（Fine-tuning）的目的以及其对移动端深度学习应用的意义。",
          "reference_answer": "微调的目的是在保留预训练模型已学习的通用特征的同时，通过训练少量顶层来适应新数据集。例如，材料中提到微调的非训练参数（Non-trainable params）远多于可训练参数（Trainable params），说明大部分特征是通用的，仅需调整顶层即可。这在移动端深度学习应用中意义重大，因为训练全部参数会消耗大量计算资源和训练时间，而微调可以减小模型更新的范围，提高效率，同时避免预训练模型在大量梯度更新中忘记已学到的通用特征，从而在移动设备上实现高性能、低资源消耗的推理。",
          "grading_criteria": "根据是否理解微调目的、是否结合参数数据进行分析，以及是否阐述其在移动端应用中的意义进行评分。"
        }
      ]
    }
  ]
}