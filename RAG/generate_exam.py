import os
import sys
import json
import yaml
import argparse
import traceback
import re
from pathlib import Path
from typing import Dict, List, Any
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

# Constants
PROMPT_FILE = Path(__file__).parent / "prompts" / "zh.yaml"

class ExamGenerator:
    def __init__(self, course_id: str, output_dir="assignments"):
        self.course_id = course_id
        self.client = self._init_openai_client()
        self.prompts = self._load_prompts()
        self.course_name = self._get_course_name()
        self.output_dir = Path(output_dir)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•(å¦‚æœä¸å­˜åœ¨)
        self.output_dir.mkdir(exist_ok=True)
        
        self.exam_data = {
            "title": f"{self.course_name}æœŸæœ«è€ƒè¯•",
            "course": self.course_name,
            "duration": "120åˆ†é’Ÿ",
            "total_score": 100,
            "sections": []
        }

    def _init_openai_client(self) -> OpenAI:
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        api_key = os.getenv("LLM_API_KEY")
        base_url = os.getenv("LLM_API_BASE")
        
        if not api_key or not base_url:
            raise ValueError("åœ¨.envæ–‡ä»¶ä¸­æœªæ‰¾åˆ°LLM_API_KEYæˆ–LLM_API_BASE")
        
        return OpenAI(
            api_key=api_key,
            base_url=base_url,
        )

    def _load_prompts(self) -> Dict:
        """ä»YAMLæ–‡ä»¶åŠ è½½æç¤ºè¯"""
        if not PROMPT_FILE.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æç¤ºè¯æ–‡ä»¶: {PROMPT_FILE}")
        
        with open(PROMPT_FILE, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def _get_course_name(self) -> str:
        """ä»å…ƒæ•°æ®æ–‡ä»¶è·å–è¯¾ç¨‹åç§°"""
        metadata_path = Path(f"./data/{self.course_id}/metadata.json")
        if metadata_path.exists():
            try:
                with open(metadata_path, "r", encoding="utf-8") as f:
                    metadata = json.load(f)
                    return metadata.get("course_name", f"è¯¾ç¨‹ {self.course_id}")
            except (json.JSONDecodeError, FileNotFoundError):
                pass
        return f"è¯¾ç¨‹ {self.course_id}"

    def _get_context_from_rag(self, query: str) -> str:
        """é€šè¿‡æŸ¥è¯¢RAGç³»ç»Ÿè·å–ä¸Šä¸‹æ–‡"""
        try:
            # Import here to avoid circular imports
            from rag_query import hybrid_retriever, format_docs
            
            # Call the hybrid retriever to get relevant documents
            docs = hybrid_retriever(query, self.course_id)
            
            # Format documents into a single string context
            context = format_docs(docs)
            
            # Truncate if too long (optional)
            max_context_length = 8000  # Adjust as needed
            if len(context) > max_context_length:
                print(f"è­¦å‘Šï¼šä¸Šä¸‹æ–‡å¤ªé•¿({len(context)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³{max_context_length}å­—ç¬¦...")
                context = context[:max_context_length] + "..."
            
            # ç¡®ä¿ä¸Šä¸‹æ–‡éç©º
            if not context.strip():
                print("è­¦å‘Šï¼šè·å–åˆ°çš„ä¸Šä¸‹æ–‡ä¸ºç©ºï¼Œä½¿ç”¨é€šç”¨æç¤ºä»£æ›¿")
                return f"æä¾›å…³äº{self.course_name}çš„æ•™å­¦èµ„æ–™ï¼ŒåŒ…å«è¯¾ç¨‹çš„å…³é”®æ¦‚å¿µå’ŒçŸ¥è¯†ç‚¹ã€‚"
                
            return context
        except Exception as e:
            print(f"è·å–RAGä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {str(e)}")
            print("ä½¿ç”¨é€šç”¨ä¸Šä¸‹æ–‡ç»§ç»­...")
            return f"æä¾›å…³äº{self.course_name}çš„æ•™å­¦èµ„æ–™ï¼ŒåŒ…å«è¯¾ç¨‹çš„å…³é”®æ¦‚å¿µå’ŒçŸ¥è¯†ç‚¹ã€‚"
            
    def _extract_questions_from_text(self, text, question_type="multiple_choice"):
        """å°è¯•ä»æ–‡æœ¬ä¸­æå–é—®é¢˜ï¼Œå³ä½¿JSONè§£æå¤±è´¥"""
        questions = []
        
        # å…ˆå°è¯•è§£æJSON
        try:
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            text = re.sub(r'```(?:json)?|```', '', text)
            
            # å°è¯•è§£æJSON
            data = json.loads(text)
            if isinstance(data, dict) and "questions" in data and isinstance(data["questions"], list):
                questions = data["questions"]
                print(f"æˆåŠŸä»JSONä¸­æå–äº† {len(questions)} é“é¢˜ç›®")
                return questions
        except Exception:
            print("æ— æ³•ä½¿ç”¨JSONè§£æï¼Œå°è¯•é€šè¿‡æ–‡æœ¬æå–...")
        
        # å¦‚æœæ— æ³•è§£æJSONï¼Œå°è¯•é€šè¿‡æ–‡æœ¬æ¨¡å¼æå–é—®é¢˜
        try:
            if question_type == "multiple_choice":
                # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…é€‰æ‹©é¢˜æ¨¡å¼
                pattern = r'"id":\s*(\d+),\s*"stem":\s*"([^"]+)",\s*"options":\s*\[\s*"([^"]+)",\s*"([^"]+)",\s*"([^"]+)",\s*"([^"]+)"\s*\],\s*"answer":\s*"([^"]+)",\s*"explanation":\s*"([^"]+)"'
                matches = re.finditer(pattern, text)
                
                for match in matches:
                    try:
                        id_num, stem, option_a, option_b, option_c, option_d, answer, explanation = match.groups()
                        question = {
                            "id": int(id_num),
                            "stem": stem,
                            "options": [option_a, option_b, option_c, option_d],
                            "answer": answer,
                            "explanation": explanation
                        }
                        questions.append(question)
                    except Exception as e:
                        print(f"è§£æé€‰æ‹©é¢˜æ—¶å‡ºé”™: {str(e)}")
                
            elif question_type == "fill_in_blank":
                # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¡«ç©ºé¢˜æ¨¡å¼
                pattern = r'"id":\s*(\d+),\s*"stem":\s*"([^"]+)",\s*"answer":\s*"([^"]+)",\s*"explanation":\s*"([^"]+)"'
                matches = re.finditer(pattern, text)
                
                for match in matches:
                    try:
                        id_num, stem, answer, explanation = match.groups()
                        question = {
                            "id": int(id_num),
                            "stem": stem,
                            "answer": answer,
                            "explanation": explanation
                        }
                        questions.append(question)
                    except Exception as e:
                        print(f"è§£æå¡«ç©ºé¢˜æ—¶å‡ºé”™: {str(e)}")
                
            elif question_type == "essay":
                # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è®ºè¿°é¢˜æ¨¡å¼
                pattern = r'"id":\s*(\d+),\s*"stem":\s*"([^"]+)",\s*"reference_answer":\s*"([^"]+)",\s*"grading_criteria":\s*"([^"]+)"'
                matches = re.finditer(pattern, text)
                
                for match in matches:
                    try:
                        id_num, stem, reference_answer, grading_criteria = match.groups()
                        question = {
                            "id": int(id_num),
                            "stem": stem,
                            "reference_answer": reference_answer,
                            "grading_criteria": grading_criteria
                        }
                        questions.append(question)
                    except Exception as e:
                        print(f"è§£æè®ºè¿°é¢˜æ—¶å‡ºé”™: {str(e)}")
            
            print(f"é€šè¿‡æ–‡æœ¬æ¨¡å¼æå–å‡º {len(questions)} é“é¢˜ç›®")
            
        except Exception as e:
            print(f"æ–‡æœ¬æå–æ–¹å¼å‡ºé”™: {str(e)}")
        
        return questions

    def _call_llm(self, prompt: str, question_type="multiple_choice") -> Dict:
        """è°ƒç”¨LLMå¹¶è¿”å›è§£æåçš„JSONå“åº”"""
        model_name = os.getenv("LLM_MODEL", "")
        if not model_name:
            raise ValueError("åœ¨.envæ–‡ä»¶ä¸­æœªæ‰¾åˆ°LLM_MODEL")
        
        try:
            print("æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆå†…å®¹...")
            
            # æ·»åŠ æ˜ç¡®çš„JSONæ ¼å¼è¦æ±‚
            prompt_with_json_format = prompt + "\n\nè¯·ç¡®ä¿è¿”å›æ ¼å¼æ­£ç¡®çš„JSONï¼Œå¿…é¡»åŒ…å«questionsæ•°ç»„ï¼Œå³ä½¿æ²¡æœ‰ä»»ä½•é¢˜ç›®ä¹Ÿåº”è¿”å›ç©ºæ•°ç»„ã€‚è¯·ä¸è¦åœ¨JSONå¤–åŒ…å«å…¶ä»–å†…å®¹ï¼Œä¸è¦æ·»åŠ é¢å¤–çš„å­—æ®µã€‚"
            
            # è®¾ç½®æ›´é«˜æ¸©åº¦ä»¥å¢åŠ åˆ›é€ æ€§ï¼Œä½†ä¸è¦å¤ªé«˜
            temperature = 0.75
            
            # å…è®¸æ›´é•¿çš„è¾“å‡ºå’Œæ›´é•¿çš„æ€è€ƒæ—¶é—´
            response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt_with_json_format}],
                response_format={"type": "json_object"},
                temperature=temperature,
                max_tokens=2000,
                timeout=120,  # å…è®¸æ›´é•¿çš„å“åº”æ—¶é—´
                seed=42,  # ä½¿ç”¨å›ºå®šçš„éšæœºç§å­ä»¥æé«˜ä¸€è‡´æ€§
            )
            
            json_text = response.choices[0].message.content
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå†…å®¹
            if not json_text.strip():
                print("è­¦å‘Š: LLMè¿”å›ç©ºå†…å®¹")
                return {"questions": []}
                
            # å°è¯•æå–é—®é¢˜ï¼ˆä¼˜å…ˆå°è¯•JSONè§£æï¼Œå¤±è´¥åˆ™ä½¿ç”¨æ–‡æœ¬æå–ï¼‰
            questions = self._extract_questions_from_text(json_text, question_type)
            
            # ç¡®ä¿æ¯ä¸ªé—®é¢˜éƒ½æœ‰å”¯ä¸€ID
            for i, q in enumerate(questions):
                if "id" not in q:
                    q["id"] = i + 1
            
            return {"questions": questions}
                
        except Exception as e:
            print(f"è°ƒç”¨LLMæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            traceback.print_exc()
            # è¿”å›é»˜è®¤ç©ºç»“æ„
            return {"questions": []}

    def generate_multiple_choice(self, num_questions=5) -> Dict:
        """ç”Ÿæˆé€‰æ‹©é¢˜"""
        print(f"\nğŸ” æ­£åœ¨ä¸ºé€‰æ‹©é¢˜æ”¶é›†ä¸Šä¸‹æ–‡...")
        context = self._get_context_from_rag(f"{self.course_name}çš„å…³é”®æ¦‚å¿µå’ŒçŸ¥è¯†ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")
        
        print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆ{num_questions}é“é€‰æ‹©é¢˜...")
        prompt_template = self.prompts["multiple_choice"]
        prompt = prompt_template.replace("{num_questions}", str(num_questions)).replace("{context}", context)
        
        # å¦‚æœä¸Šä¸‹æ–‡å†…å®¹è¾ƒå°‘ï¼Œå¢åŠ æ›´å¤šå¼•å¯¼
        if len(context) < 200:
            prompt += f"\n\nå³ä½¿ä¸Šä¸‹æ–‡ä¿¡æ¯æœ‰é™ï¼Œä¹Ÿè¯·å°½åŠ›ç”Ÿæˆ{num_questions}é“é«˜è´¨é‡çš„é€‰æ‹©é¢˜ã€‚å¯ä»¥ä½¿ç”¨ä½ çš„çŸ¥è¯†é€‚å½“æ‰©å±•ç›¸å…³å†…å®¹ã€‚"
            
        # ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒï¼Œå¢åŠ ç²¾ç¡®æ€§
        prompt += "\n\nè¯·æ³¨æ„:\n1. æ¯ä¸ªé—®é¢˜å¿…é¡»æœ‰å››ä¸ªé€‰é¡¹(Aã€Bã€Cã€D)\n2. æ¯ä¸ªé—®é¢˜å¿…é¡»æœ‰æ˜ç¡®çš„ç­”æ¡ˆ(ç­”æ¡ˆä¸ºé€‰é¡¹çš„å­—æ¯ï¼Œå¦‚'A')\n3. æ¯ä¸ªé—®é¢˜å¿…é¡»æœ‰è§£é‡Š\n4. ä»¥æ ‡å‡†JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ é¢å¤–å­—æ®µ\n5. å‡è®¾æˆ‘æ˜¯TensorFlow Liteå’Œç§»åŠ¨ç«¯AIåº”ç”¨æ–¹é¢çš„ä¸“å®¶ï¼Œè¯·ç”Ÿæˆé€‚åˆæˆ‘çš„é¢˜ç›®"
            
        # å°è¯•å¤šæ¬¡è°ƒç”¨ä»¥è·å–æœ‰æ•ˆç»“æœ
        max_attempts = 3
        result = {"questions": []}
        
        for attempt in range(max_attempts):
            if attempt > 0:
                print(f"ç¬¬{attempt+1}æ¬¡å°è¯•ç”Ÿæˆé€‰æ‹©é¢˜...")
            
            attempt_result = self._call_llm(prompt, "multiple_choice")
            if attempt_result.get("questions") and len(attempt_result["questions"]) > 0:
                result = attempt_result
                break
            
            if attempt < max_attempts - 1:
                print(f"æœªèƒ½ç”Ÿæˆé€‰æ‹©é¢˜ï¼Œå°†è¿›è¡Œé‡è¯•...")
        
        section = {
            "type": "multiple_choice",
            "description": "é€‰æ‹©é¢˜ï¼šè¯·åœ¨æ¯å°é¢˜ç»™å‡ºçš„é€‰é¡¹ä¸­é€‰å‡ºä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆã€‚",
            "score_per_question": 4,  # æ¯é“é¢˜4åˆ†
            "questions": result.get("questions", [])
        }
        
        self.exam_data["sections"].append(section)
        print(f"âœ… å·²ç”Ÿæˆ{len(section['questions'])}é“é€‰æ‹©é¢˜ã€‚")
        
        # ç«‹å³ä¿å­˜å½“å‰é˜¶æ®µç»“æœ
        self._save_section_results("multiple_choice")
        
        return result

    def generate_fill_in_blank(self, num_questions=5) -> Dict:
        """ç”Ÿæˆå¡«ç©ºé¢˜"""
        print(f"\nğŸ” æ­£åœ¨ä¸ºå¡«ç©ºé¢˜æ”¶é›†ä¸Šä¸‹æ–‡...")
        context = self._get_context_from_rag(f"{self.course_name}ä¸­é‡è¦çš„æœ¯è¯­ã€å®šä¹‰å’Œå…¬å¼æ˜¯ä»€ä¹ˆï¼Ÿ")
        
        print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆ{num_questions}é“å¡«ç©ºé¢˜...")
        prompt_template = self.prompts["fill_in_blank"]
        prompt = prompt_template.replace("{num_questions}", str(num_questions)).replace("{context}", context)
        
        # å¦‚æœä¸Šä¸‹æ–‡å†…å®¹è¾ƒå°‘ï¼Œå¢åŠ æ›´å¤šå¼•å¯¼
        if len(context) < 200:
            prompt += f"\n\nå³ä½¿ä¸Šä¸‹æ–‡ä¿¡æ¯æœ‰é™ï¼Œä¹Ÿè¯·å°½åŠ›ç”Ÿæˆ{num_questions}é“é«˜è´¨é‡çš„å¡«ç©ºé¢˜ã€‚å¯ä»¥ä½¿ç”¨ä½ çš„çŸ¥è¯†é€‚å½“æ‰©å±•ç›¸å…³å†…å®¹ã€‚"
            
        # ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒï¼Œå¢åŠ ç²¾ç¡®æ€§
        prompt += "\n\nè¯·æ³¨æ„:\n1. æ¯ä¸ªå¡«ç©ºé¢˜åªæœ‰ä¸€ä¸ªç©ºï¼Œç”¨'_____'è¡¨ç¤º\n2. æ¯ä¸ªé—®é¢˜å¿…é¡»æœ‰æ˜ç¡®çš„ç­”æ¡ˆ\n3. æ¯ä¸ªé—®é¢˜å¿…é¡»æœ‰è§£é‡Š\n4. ä»¥æ ‡å‡†JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ é¢å¤–å­—æ®µ\n5. é¢˜ç›®åº”è¯¥å›´ç»•TensorFlow Liteå’Œç§»åŠ¨ç«¯AIåº”ç”¨çš„æ ¸å¿ƒæ¦‚å¿µ"
            
        # å°è¯•å¤šæ¬¡è°ƒç”¨ä»¥è·å–æœ‰æ•ˆç»“æœ
        max_attempts = 3
        result = {"questions": []}
        
        for attempt in range(max_attempts):
            if attempt > 0:
                print(f"ç¬¬{attempt+1}æ¬¡å°è¯•ç”Ÿæˆå¡«ç©ºé¢˜...")
            
            attempt_result = self._call_llm(prompt, "fill_in_blank")
            if attempt_result.get("questions") and len(attempt_result["questions"]) > 0:
                result = attempt_result
                break
            
            if attempt < max_attempts - 1:
                print(f"æœªèƒ½ç”Ÿæˆå¡«ç©ºé¢˜ï¼Œå°†è¿›è¡Œé‡è¯•...")
        
        section = {
            "type": "fill_in_blank",
            "description": "å¡«ç©ºé¢˜ï¼šè¯·åœ¨æ¨ªçº¿ä¸Šå¡«å†™æ­£ç¡®çš„å†…å®¹ã€‚",
            "score_per_question": 4,  # æ¯é“é¢˜4åˆ†
            "questions": result.get("questions", [])
        }
        
        self.exam_data["sections"].append(section)
        print(f"âœ… å·²ç”Ÿæˆ{len(section['questions'])}é“å¡«ç©ºé¢˜ã€‚")
        
        # ç«‹å³ä¿å­˜å½“å‰é˜¶æ®µç»“æœ
        self._save_section_results("fill_in_blank")
        
        return result

    def generate_essay_questions(self, num_questions=3) -> Dict:
        """ç”Ÿæˆè®ºè¿°é¢˜"""
        print(f"\nğŸ” æ­£åœ¨ä¸ºè®ºè¿°é¢˜æ”¶é›†ä¸Šä¸‹æ–‡...")
        context = self._get_context_from_rag(f"{self.course_name}ä¸­éœ€è¦æ·±å…¥ç†è§£çš„å¤æ‚ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ")
        
        print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆ{num_questions}é“è®ºè¿°é¢˜...")
        prompt_template = self.prompts["essay_questions"]
        prompt = prompt_template.replace("{num_questions}", str(num_questions)).replace("{context}", context)
        
        # å¦‚æœä¸Šä¸‹æ–‡å†…å®¹è¾ƒå°‘ï¼Œå¢åŠ æ›´å¤šå¼•å¯¼
        if len(context) < 200:
            prompt += f"\n\nå³ä½¿ä¸Šä¸‹æ–‡ä¿¡æ¯æœ‰é™ï¼Œä¹Ÿè¯·å°½åŠ›ç”Ÿæˆ{num_questions}é“é«˜è´¨é‡çš„è®ºè¿°é¢˜ã€‚å¯ä»¥ä½¿ç”¨ä½ çš„çŸ¥è¯†é€‚å½“æ‰©å±•ç›¸å…³å†…å®¹ã€‚"
            
        # ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒï¼Œå¢åŠ ç²¾ç¡®æ€§
        prompt += "\n\nè¯·æ³¨æ„:\n1. æ¯ä¸ªé¢˜ç›®å¿…é¡»æœ‰stemï¼ˆé¢˜å¹²ï¼‰\n2. æ¯ä¸ªé¢˜ç›®å¿…é¡»æœ‰reference_answerï¼ˆå‚è€ƒç­”æ¡ˆï¼‰\n3. æ¯ä¸ªé¢˜ç›®å¿…é¡»æœ‰grading_criteriaï¼ˆè¯„åˆ†æ ‡å‡†ï¼‰\n4. ä»¥æ ‡å‡†JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ é¢å¤–å­—æ®µ\n5. å›´ç»•TensorFlow Liteå’Œç§»åŠ¨ç«¯æ·±åº¦å­¦ä¹ åº”ç”¨çš„å®è·µé—®é¢˜è®¾ç½®è®ºè¿°é¢˜"
            
        # å°è¯•å¤šæ¬¡è°ƒç”¨ä»¥è·å–æœ‰æ•ˆç»“æœ
        max_attempts = 3
        result = {"questions": []}
        
        for attempt in range(max_attempts):
            if attempt > 0:
                print(f"ç¬¬{attempt+1}æ¬¡å°è¯•ç”Ÿæˆè®ºè¿°é¢˜...")
            
            attempt_result = self._call_llm(prompt, "essay")
            if attempt_result.get("questions") and len(attempt_result["questions"]) > 0:
                result = attempt_result
                break
            
            if attempt < max_attempts - 1:
                print(f"æœªèƒ½ç”Ÿæˆè®ºè¿°é¢˜ï¼Œå°†è¿›è¡Œé‡è¯•...")
        
        section = {
            "type": "essay",
            "description": "è®ºè¿°é¢˜ï¼šè¯·æŒ‰è¦æ±‚å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚",
            "score_per_question": 20,  # æ¯é“é¢˜20åˆ†
            "questions": result.get("questions", [])
        }
        
        self.exam_data["sections"].append(section)
        print(f"âœ… å·²ç”Ÿæˆ{len(section['questions'])}é“è®ºè¿°é¢˜ã€‚")
        
        # ç«‹å³ä¿å­˜å½“å‰é˜¶æ®µç»“æœ
        self._save_section_results("essay")
        
        return result
        
    def _save_section_results(self, section_type: str) -> None:
        """ä¿å­˜å½“å‰ç”Ÿæˆçš„éƒ¨åˆ†"""
        # æ‰¾åˆ°å½“å‰èŠ‚
        current_section = None
        for section in self.exam_data["sections"]:
            if section["type"] == section_type:
                current_section = section
                break
        
        if current_section is None:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°ç±»å‹ä¸º {section_type} çš„éƒ¨åˆ†")
            return
            
        # åˆ›å»ºå•ç‹¬çš„æ–‡ä»¶å
        section_file = self.output_dir / f"{self.course_id}_{section_type}.json"
        
        # ä¿å­˜è¯¥éƒ¨åˆ†
        with open(section_file, "w", encoding="utf-8") as f:
            json.dump(current_section, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å·²ä¿å­˜{section_type}éƒ¨åˆ†è‡³ {section_file}")
        
        # æ‰“å°ç”Ÿæˆçš„é¢˜ç›®é¢„è§ˆ
        questions = current_section.get("questions", [])
        if questions:
            print("\n--- ç”Ÿæˆçš„é¢˜ç›®é¢„è§ˆ ---")
            for q in questions[:2]:  # åªé¢„è§ˆå‰ä¸¤é¢˜
                print(f"é¢˜ç›® {q['id']}: {q['stem'][:50]}..." if len(q['stem']) > 50 else f"é¢˜ç›® {q['id']}: {q['stem']}")
                if "options" in q:
                    print(f"  é€‰é¡¹: {', '.join(o[:20] + '...' if len(o) > 20 else o for o in q['options'][:2])}")
                    print(f"  ç­”æ¡ˆ: {q['answer']}")
                elif "answer" in q:
                    print(f"  ç­”æ¡ˆ: {q['answer']}")
        else:
            print("æœªç”Ÿæˆä»»ä½•é¢˜ç›®ï¼")

    def save_exam(self, output_path=None) -> str:
        """ä¿å­˜ç”Ÿæˆçš„è€ƒè¯•åˆ°JSONæ–‡ä»¶"""
        if output_path is None:
            output_path = self.output_dir / f"exam_{self.course_id}.json"
        else:
            # ç¡®ä¿è¾“å‡ºè·¯å¾„æ˜¯Pathå¯¹è±¡
            output_path = Path(output_path)
            # å¦‚æœåªæä¾›äº†æ–‡ä»¶åï¼Œåˆ™æ”¾åœ¨è¾“å‡ºç›®å½•ä¸‹
            if not output_path.is_absolute() and len(output_path.parts) == 1:
                output_path = self.output_dir / output_path
        
        # è®¡ç®—å®é™…æ€»åˆ†
        total_score = 0
        for section in self.exam_data["sections"]:
            total_score += section["score_per_question"] * len(section["questions"])
        self.exam_data["total_score"] = total_score
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(self.exam_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è€ƒè¯•å·²ä¿å­˜è‡³ {output_path}")
        return str(output_path)
    
    def print_section_summary(self, section_type: str) -> None:
        """æ‰“å°ç”Ÿæˆçš„éƒ¨åˆ†æ‘˜è¦"""
        for section in self.exam_data["sections"]:
            if section["type"] == section_type:
                questions = section["questions"]
                print(f"\n--- {section['description']} ---")
                for q in questions:
                    print(f"é¢˜ç›® {q['id']}: {q['stem'][:50]}..." if len(q['stem']) > 50 else f"é¢˜ç›® {q['id']}: {q['stem']}")

def generate_final_exam(course_id, output_path=None, output_dir="assignments"):
    """ä¸ºæŒ‡å®šè¯¾ç¨‹ç”Ÿæˆå®Œæ•´è€ƒè¯•"""
    generator = ExamGenerator(course_id, output_dir=output_dir)
    
    try:
        # æ­¥éª¤1: ç”Ÿæˆé€‰æ‹©é¢˜
        generator.generate_multiple_choice(num_questions=10)
        generator.print_section_summary("multiple_choice")
        
        # æ­¥éª¤2: ç”Ÿæˆå¡«ç©ºé¢˜
        generator.generate_fill_in_blank(num_questions=5)
        generator.print_section_summary("fill_in_blank")
        
        # æ­¥éª¤3: ç”Ÿæˆè®ºè¿°é¢˜
        generator.generate_essay_questions(num_questions=3)
        generator.print_section_summary("essay")
        
        # ä¿å­˜å®Œæ•´è€ƒè¯•
        output_file = generator.save_exam(output_path)
        
        print(f"\nâœ¨ è€ƒè¯•ç”Ÿæˆå®Œæˆ! âœ¨")
        print(f"æ€»é¢˜ç›®æ•°: {sum(len(section['questions']) for section in generator.exam_data['sections'])}")
        print(f"æ€»åˆ†: {generator.exam_data['total_score']}")
        
        return output_file
    except Exception as e:
        print(f"ç”Ÿæˆè€ƒè¯•æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()
        # å°½é‡ä¿å­˜å·²ç»ç”Ÿæˆçš„å†…å®¹
        try:
            if generator.exam_data["sections"]:
                output_file = generator.save_exam(output_path)
                print(f"å·²ä¿å­˜éƒ¨åˆ†ç”Ÿæˆçš„è€ƒè¯•å†…å®¹åˆ° {output_file}")
        except:
            print("ä¿å­˜éƒ¨åˆ†ç»“æœå¤±è´¥")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ä¸ºè¯¾ç¨‹ç”ŸæˆæœŸæœ«è€ƒè¯•ã€‚")
    parser.add_argument("--course_id", type=str, required=True, help="è¦ç”Ÿæˆè€ƒè¯•çš„è¯¾ç¨‹IDã€‚")
    parser.add_argument("--output", type=str, help="ä¿å­˜ç”Ÿæˆçš„è€ƒè¯•JSONæ–‡ä»¶çš„è·¯å¾„ã€‚")
    parser.add_argument("--output_dir", type=str, default="assignments", help="ä¿å­˜ç”Ÿæˆçš„è€ƒè¯•æ–‡ä»¶çš„ç›®å½•ã€‚")
    args = parser.parse_args()
    
    generate_final_exam(args.course_id, args.output, args.output_dir) 